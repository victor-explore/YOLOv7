{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOJnx2Ctbmzf1guSm7AsBKo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["### **Step 1: Setup Your Google Colab Environment**"],"metadata":{"id":"1Xi_hNpsi_N6"}},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tYZynoF7iVQm","executionInfo":{"status":"ok","timestamp":1712672213657,"user_tz":-330,"elapsed":87097,"user":{"displayName":"Investing Filter","userId":"00097480192575946567"}},"outputId":"2bd2a992-2669-4d8f-e104-9ec38d19f1ba"},"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA (GPU support) is available and enabled!\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.17.1+cu121)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.3)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch)\n","  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n","Setup completed.\n"]}],"source":["import torch\n","if torch.cuda.is_available():\n","    print(\"CUDA (GPU support) is available and enabled!\")\n","else:\n","    print(\"CUDA is not available. Check your runtime type and ensure it's set to GPU.\")\n","\n","# Install PyTorch\n","!pip install torch torchvision torchaudio\n","\n","print(\"Setup completed.\")\n"]},{"cell_type":"code","source":["# Clone the YOLOv7 repository\n","!git clone https://github.com/WongKinYiu/yolov7.git\n","%cd yolov7\n","\n","# Install the requirements\n","!pip install -r requirements.txt\n","\n","print(\"YOLOv7 repository has been cloned and requirements are installed.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"6HRD4gNYoAQc","executionInfo":{"status":"ok","timestamp":1712672237761,"user_tz":-330,"elapsed":24114,"user":{"displayName":"Investing Filter","userId":"00097480192575946567"}},"outputId":"c3bb5544-08f0-4811-8d6d-a3bf2b694e4b"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'yolov7'...\n","remote: Enumerating objects: 1197, done.\u001b[K\n","remote: Total 1197 (delta 0), reused 0 (delta 0), pack-reused 1197\u001b[K\n","Receiving objects: 100% (1197/1197), 74.23 MiB | 13.36 MiB/s, done.\n","Resolving deltas: 100% (519/519), done.\n","/content/yolov7\n","Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (3.7.1)\n","Collecting numpy<1.24.0,>=1.18.5 (from -r requirements.txt (line 5))\n","  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (4.8.0.76)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (9.4.0)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (6.0.1)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (2.31.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (1.11.4)\n","Requirement already satisfied: torch!=1.12.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (2.2.1+cu121)\n","Requirement already satisfied: torchvision!=0.13.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (0.17.1+cu121)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (4.66.2)\n","Requirement already satisfied: protobuf<4.21.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (3.20.3)\n","Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (2.15.2)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 21)) (2.0.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (0.13.1)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 34)) (7.34.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 35)) (5.9.5)\n","Collecting thop (from -r requirements.txt (line 36))\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (4.50.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (24.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2024.2.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.13.3)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (12.4.127)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.62.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.6)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (67.7.2)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.16.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.0.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 21)) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 21)) (2024.1)\n","Collecting jedi>=0.16 (from ipython->-r requirements.txt (line 34))\n","  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (5.7.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (3.0.43)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (2.16.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (0.1.6)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (4.9.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.3.1)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->-r requirements.txt (line 34)) (0.8.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->-r requirements.txt (line 34)) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r requirements.txt (line 34)) (0.2.13)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (1.3.0)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.6.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.2.2)\n","Installing collected packages: numpy, jedi, thop\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.25.2\n","    Uninstalling numpy-1.25.2:\n","      Successfully uninstalled numpy-1.25.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n","pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed jedi-0.19.1 numpy-1.23.5 thop-0.1.1.post2209072238\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]},"id":"c2368fd4dbaa40eb94757a3bee0cbf44"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["YOLOv7 repository has been cloned and requirements are installed.\n"]}]},{"cell_type":"code","source":["import os\n","os.kill(os.getpid(), 9)"],"metadata":{"id":"QJY-O2M5oX0f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Example to check PyTorch version\n","import torch\n","print(torch.__version__)\n","\n","# Check numpy version\n","import numpy\n","print(numpy.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XynmHr87obTj","executionInfo":{"status":"ok","timestamp":1712672278861,"user_tz":-330,"elapsed":2244,"user":{"displayName":"Investing Filter","userId":"00097480192575946567"}},"outputId":"a007082b-b50e-4bf0-ac48-6ddf5eef53f3"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["2.2.1+cu121\n","1.23.5\n"]}]},{"cell_type":"markdown","source":["### **Step 2: Prepare dataset**"],"metadata":{"id":"2_AIOa_ao7eC"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"enO09rh_pA_e","executionInfo":{"status":"ok","timestamp":1712672299207,"user_tz":-330,"elapsed":19805,"user":{"displayName":"Investing Filter","userId":"00097480192575946567"}},"outputId":"af1fa45e-a439-409b-87ac-5a33b4467797"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["dataset_path = '\"/content/drive/MyDrive/AIP Assignment 4/object_detection\"'\n","\n","# Check a few files to ensure the structure is correct\n","!ls {dataset_path}/train | head -5\n","!ls {dataset_path}/val | head -5\n","!cat {dataset_path}/data.yaml"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"er2hzaThpknj","executionInfo":{"status":"ok","timestamp":1712672301519,"user_tz":-330,"elapsed":2315,"user":{"displayName":"Investing Filter","userId":"00097480192575946567"}},"outputId":"78296812-fbb0-48d5-91f4-5af4b238ab9d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["images\n","labels\n","labels.cache\n","images\n","labels\n","labels.cache\n","train: /content/drive/MyDrive/AIP Assignment 4/object_detection/train/images\n","val: /content/drive/MyDrive/AIP Assignment 4/object_detection/val/images/\n","test: /content/drive/MyDrive/AIP Assignment 4/object_detection/test/images/\n","\n","nc: 7\n","names: ['fish', 'jellyfish', 'penguin', 'puffin', 'shark', 'starfish', 'stingray']"]}]},{"cell_type":"markdown","source":[" structure defined in data.yaml, including paths to training, validation, and testing images, the number of classes (nc), and their names:\n","\n","\n","*   aths: Specifies where to find the images for each data split (training, validation, testing). YOLOv7 will use these paths to load data.\n","*   nc: The number of classes (7 in your case) tells the model how many different objects it should learn to detect.\n","*   names: Lists the names of the classes (['fish', 'jellyfish', 'penguin', 'puffin', 'shark', 'starfish', 'stingray']). These names are used to label detected objects and correspond to the class IDs in annotation files.\n","\n","\n","\n"],"metadata":{"id":"pKRXw7T0K6S5"}},{"cell_type":"markdown","source":["### **Step 3: Training**"],"metadata":{"id":"-ex7GijQqDb_"}},{"cell_type":"code","source":["import os\n","\n","# Check the current working directory\n","print(\"Current working directory:\", os.getcwd())\n","\n","# Adjust the path below according to where the yolov7 repo is cloned in Google Drive\n","yolov7_dir_path = '/content/yolov7'\n","os.chdir(yolov7_dir_path)\n","\n","print(\"Changed directory to:\", os.getcwd())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PIeVidZsqguD","executionInfo":{"status":"ok","timestamp":1712672301520,"user_tz":-330,"elapsed":12,"user":{"displayName":"Investing Filter","userId":"00097480192575946567"}},"outputId":"1f09b213-9ea1-4d37-e9f9-8f36391494de"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Current working directory: /content\n","Changed directory to: /content/yolov7\n"]}]},{"cell_type":"code","source":["!ls /content/yolov7/cfg"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HtggRs5grxp1","executionInfo":{"status":"ok","timestamp":1712672304755,"user_tz":-330,"elapsed":4,"user":{"displayName":"Investing Filter","userId":"00097480192575946567"}},"outputId":"e9d36a49-b2aa-48d3-8e97-59bf1c311ef8"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["baseline  deploy  training\n"]}]},{"cell_type":"code","source":["!find /content/yolov7 -type f -name \"*.yaml\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cNfpNfbetWc3","executionInfo":{"status":"ok","timestamp":1712672305397,"user_tz":-330,"elapsed":4,"user":{"displayName":"Investing Filter","userId":"00097480192575946567"}},"outputId":"78f2482e-9873-49cf-dbe0-68fd6b278438"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/yolov7/utils/google_app_engine/app.yaml\n","/content/yolov7/data/hyp.scratch.p6.yaml\n","/content/yolov7/data/coco.yaml\n","/content/yolov7/data/hyp.scratch.custom.yaml\n","/content/yolov7/data/hyp.scratch.p5.yaml\n","/content/yolov7/data/hyp.scratch.tiny.yaml\n","/content/yolov7/cfg/baseline/x50-csp.yaml\n","/content/yolov7/cfg/baseline/yolov4-csp.yaml\n","/content/yolov7/cfg/baseline/yolor-w6.yaml\n","/content/yolov7/cfg/baseline/yolov3-spp.yaml\n","/content/yolov7/cfg/baseline/yolov3.yaml\n","/content/yolov7/cfg/baseline/yolor-csp-x.yaml\n","/content/yolov7/cfg/baseline/yolor-csp.yaml\n","/content/yolov7/cfg/baseline/yolor-e6.yaml\n","/content/yolov7/cfg/baseline/yolor-p6.yaml\n","/content/yolov7/cfg/baseline/r50-csp.yaml\n","/content/yolov7/cfg/baseline/yolor-d6.yaml\n","/content/yolov7/cfg/training/yolov7x.yaml\n","/content/yolov7/cfg/training/yolov7-d6.yaml\n","/content/yolov7/cfg/training/yolov7.yaml\n","/content/yolov7/cfg/training/yolov7-tiny.yaml\n","/content/yolov7/cfg/training/yolov7-e6e.yaml\n","/content/yolov7/cfg/training/yolov7-w6.yaml\n","/content/yolov7/cfg/training/yolov7-e6.yaml\n","/content/yolov7/cfg/deploy/yolov7x.yaml\n","/content/yolov7/cfg/deploy/yolov7-tiny-silu.yaml\n","/content/yolov7/cfg/deploy/yolov7-d6.yaml\n","/content/yolov7/cfg/deploy/yolov7.yaml\n","/content/yolov7/cfg/deploy/yolov7-tiny.yaml\n","/content/yolov7/cfg/deploy/yolov7-e6e.yaml\n","/content/yolov7/cfg/deploy/yolov7-w6.yaml\n","/content/yolov7/cfg/deploy/yolov7-e6.yaml\n"]}]},{"cell_type":"code","source":["!python train.py --img 640 --batch 16 --epochs 10 --data \"/content/drive/MyDrive/AIP Assignment 4/object_detection/data.yaml\" --cfg cfg/deploy/yolov7.yaml --weights yolov7.pt --device 0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zkZCNk1uq5PP","executionInfo":{"status":"ok","timestamp":1712673143904,"user_tz":-330,"elapsed":834835,"user":{"displayName":"Investing Filter","userId":"00097480192575946567"}},"outputId":"d49fe56d-26ae-44d2-9d05-b8e5fe9352d3"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-04-09 14:18:32.392576: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-04-09 14:18:32.392622: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-04-09 14:18:32.512062: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-04-09 14:18:32.734320: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-04-09 14:18:33.812443: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","YOLOR ðŸš€ v0.1-128-ga207844 torch 2.2.1+cu121 CUDA:0 (Tesla T4, 15102.0625MB)\n","\n","Namespace(weights='yolov7.pt', cfg='cfg/deploy/yolov7.yaml', data='/content/drive/MyDrive/AIP Assignment 4/object_detection/data.yaml', hyp='data/hyp.scratch.p5.yaml', epochs=10, batch_size=16, img_size=[640, 640], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='0', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=8, project='runs/train', entity=None, name='exp', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', freeze=[0], v5_metric=False, world_size=1, global_rank=-1, save_dir='runs/train/exp', total_batch_size=16)\n","\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15, loss_ota=1\n","\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n","Downloading https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt to yolov7.pt...\n","100% 72.1M/72.1M [00:00<00:00, 344MB/s]\n","\n","Overriding model.yaml nc=80 with nc=7\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n","  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n","  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n"," 12                -1  1         0  models.common.MP                        []                            \n"," 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n"," 25                -1  1         0  models.common.MP                        []                            \n"," 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n"," 38                -1  1         0  models.common.MP                        []                            \n"," 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n"," 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n"," 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n"," 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n"," 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n"," 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n"," 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n"," 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n"," 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n"," 76                -1  1         0  models.common.MP                        []                            \n"," 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n"," 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n"," 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n"," 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n"," 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 89                -1  1         0  models.common.MP                        []                            \n"," 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n"," 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n"," 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n"," 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n"," 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n","100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n","101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n","102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n","103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n","104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n","105   [102, 103, 104]  1     64620  models.yolo.Detect                      [7, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3549.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","Model Summary: 407 layers, 37227020 parameters, 37227020 gradients, 105.2 GFLOPS\n","\n","Transferred 552/560 items from yolov7.pt\n","Scaled weight_decay = 0.0005\n","Optimizer groups: 95 .bias, 95 conv.weight, 92 other\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/drive/MyDrive/AIP Assignment 4/object_detection/train/labels.cache' images and labels... 448 found, 0 missing, 1 empty, 0 corrupted: 100% 448/448 [00:00<?, ?it/s]\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/drive/MyDrive/AIP Assignment 4/object_detection/val/labels.cache' images and labels... 127 found, 0 missing, 0 empty, 0 corrupted: 100% 127/127 [00:00<?, ?it/s]\n","\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 5.03, Best Possible Recall (BPR) = 0.9991\n","Image sizes 640 train, 640 test\n","Using 2 dataloader workers\n","Logging results to runs/train/exp\n","Starting training for 10 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       0/9     12.8G   0.08533   0.02449    0.0324    0.1422       282       640: 100% 28/28 [03:23<00:00,  7.26s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:20<00:00,  5.01s/it]\n","                 all         127         909     0.00827     0.00251    0.000374    6.85e-05\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       1/9     12.9G    0.0786   0.02343   0.02999     0.132       360       640: 100% 28/28 [00:51<00:00,  1.83s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:04<00:00,  1.23s/it]\n","                 all         127         909      0.0115      0.0426     0.00362    0.000976\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       2/9     11.3G   0.07155   0.02516    0.0272    0.1239       455       640: 100% 28/28 [00:53<00:00,  1.90s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.04it/s]\n","                 all         127         909      0.0585      0.0877      0.0237     0.00543\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       3/9     12.7G   0.06497   0.02779    0.0255    0.1183       370       640: 100% 28/28 [00:51<00:00,  1.86s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:05<00:00,  1.30s/it]\n","                 all         127         909      0.0793       0.192      0.0564      0.0186\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       4/9     12.7G    0.0581   0.02658   0.02509    0.1098       319       640: 100% 28/28 [00:53<00:00,  1.92s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:04<00:00,  1.04s/it]\n","                 all         127         909       0.157       0.212       0.126      0.0462\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       5/9     12.7G   0.05285   0.02601   0.02417     0.103       238       640: 100% 28/28 [00:51<00:00,  1.83s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:04<00:00,  1.18s/it]\n","                 all         127         909       0.217       0.257        0.18      0.0696\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       6/9     12.7G   0.05209   0.02401    0.0252    0.1013       342       640: 100% 28/28 [00:53<00:00,  1.91s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.06it/s]\n","                 all         127         909       0.221       0.256       0.181      0.0611\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       7/9     12.7G   0.04918   0.02385   0.02377    0.0968       204       640: 100% 28/28 [00:49<00:00,  1.78s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:05<00:00,  1.39s/it]\n","                 all         127         909        0.24        0.32       0.229       0.102\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       8/9     12.7G   0.04595   0.02593   0.02351   0.09539       297       640: 100% 28/28 [00:53<00:00,  1.90s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:04<00:00,  1.02s/it]\n","                 all         127         909       0.273       0.327       0.263       0.116\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       9/9     12.7G   0.04485   0.02628   0.02287     0.094       382       640: 100% 28/28 [00:51<00:00,  1.82s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:09<00:00,  2.32s/it]\n","                 all         127         909       0.254       0.415        0.29       0.143\n","                fish         127         459       0.224       0.754       0.421        0.18\n","           jellyfish         127         155       0.469        0.71       0.629       0.307\n","             penguin         127         104       0.268       0.375       0.267      0.0933\n","              puffin         127          74       0.133      0.0054      0.0761      0.0361\n","               shark         127          57       0.131       0.456       0.135      0.0632\n","            starfish         127          27       0.437       0.481       0.388       0.241\n","            stingray         127          33       0.117       0.121       0.113      0.0768\n","10 epochs completed in 0.226 hours.\n","\n","Optimizer stripped from runs/train/exp/weights/last.pt, 74.8MB\n","Optimizer stripped from runs/train/exp/weights/best.pt, 74.8MB\n"]}]},{"cell_type":"markdown","source":["\n","*   mAP@ 0.5IoU: 29.1%\n","*   mAP@[0.5:0.95]IoU: 13.7%\n","\n","---\n"],"metadata":{"id":"lqmDatCVyV1O"}},{"cell_type":"markdown","source":["\n","\n","*   The dataset has 448 training images and 127 validation images\n","*   The model used is YOLOv7 with the configuration specified in \"cfg/deploy/yolov7.yaml\". The model has 407 layers and 37,227,020 parameters.\n","*   Training hyperparameters:\n","Image size: 640x640\n","Batch size: 16\n","Number of epochs: 10\n","*   GPU utilization: The training utilized a GPU (Tesla T4) with around 12.5GB of memory\n","*   Training progress:\n","The model was evaluated on the validation set after each epoch.\n","The performance metrics (mAP@0.5 and mAP@0.5:0.95) improved over the epochs, indicating that the model was learning and generalizing better.\n","In the final epoch, the model achieved an mAP@0.5 of 0.291 and mAP@0.5:0.95 of 0.137 on the validation set.\n","*   Class-wise performance:\n","The model achieved varying performance for different object classes.\n","The \"jellyfish\" class had the highest precision (0.551) and recall (0.697), while the \"stingray\" class had zero precision and recall.\n","*   Training time: The training took approximately 0.185 hours (11 minutes) to complete 10 epochs.\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"fq1vjNwfMVr9"}},{"cell_type":"markdown","source":["### **Step5: Qualitative tests**"],"metadata":{"id":"vp6OWSbDzktF"}},{"cell_type":"code","source":["!pip install PyYAML"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b70JEnrRfmGw","executionInfo":{"status":"ok","timestamp":1712676832859,"user_tz":-330,"elapsed":5678,"user":{"displayName":"Investing Filter","userId":"00097480192575946567"}},"outputId":"ff5e5fae-c630-4e98-8872-b977371bc902"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (6.0.1)\n"]}]},{"cell_type":"code","source":["import torch\n","import yaml  # Import the yaml module\n","from models.experimental import attempt_load  # YOLOv7's specific function for model loading\n","from utils.general import check_img_size, set_logging\n","from utils.torch_utils import select_device\n","\n","# Set up logging\n","set_logging()\n","\n","# Specify the path to trained weights and configuration file\n","weights_path = '/content/yolov7/runs/train/exp/weights/best.pt'\n","device = select_device('0')\n","\n","# Load the model\n","model = attempt_load(weights_path, map_location=device)\n","print(f\"Model loaded successfully from {weights_path}\")\n","\n","# Ensure model is in evaluation mode\n","model.eval()\n","print(\"Model set to evaluation mode\")\n","\n","# Get class names from the dataset\n","data_yaml_path = '/content/drive/MyDrive/AIP Assignment 4/object_detection/data.yaml'\n","with open(data_yaml_path, 'r') as file:\n","    data = yaml.safe_load(file)\n","class_names = data['names']\n","print(f\"Class names loaded: {class_names}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lEY9-IpafpYO","executionInfo":{"status":"ok","timestamp":1712676883991,"user_tz":-330,"elapsed":1568,"user":{"displayName":"Investing Filter","userId":"00097480192575946567"}},"outputId":"1975d19b-55df-46ca-f7ee-0bbd92c2f846"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Fusing layers... \n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","Model loaded successfully from /content/yolov7/runs/train/exp/weights/best.pt\n","Model set to evaluation mode\n","Class names loaded: ['fish', 'jellyfish', 'penguin', 'puffin', 'shark', 'starfish', 'stingray']\n"]}]},{"cell_type":"code","source":["!pip install torch torchvision matplotlib"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DX0CgdPtf1mX","executionInfo":{"status":"ok","timestamp":1712676931136,"user_tz":-330,"elapsed":5615,"user":{"displayName":"Investing Filter","userId":"00097480192575946567"}},"outputId":"7b49a73c-ed5b-4cf6-a727-2096de3392c9"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.17.1+cu121)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.3)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.50.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}]},{"cell_type":"code","source":["import torch\n","from PIL import Image\n","from torchvision import transforms\n","import matplotlib.pyplot as plt\n","\n","# Define a transform to resize and normalize the image\n","transform = transforms.Compose([\n","    transforms.Resize((640, 640)),\n","    transforms.ToTensor(),\n","])\n","\n","# Load and transform images\n","img_paths = ['/content/drive/MyDrive/AIP Assignment 4/object_detection/test/images/IMG_2289_jpeg_jpg.rf.fe2a7a149e7b11f2313f5a7b30386e85.jpg', '/content/drive/MyDrive/AIP Assignment 4/object_detection/test/images/IMG_2301_jpeg_jpg.rf.2c19ae5efbd1f8611b5578125f001695.jpg', '/content/drive/MyDrive/AIP Assignment 4/object_detection/test/images/IMG_2319_jpeg_jpg.rf.6e20bf97d17b74a8948aa48776c40454.jpg']\n","images = [transform(Image.open(img_path).convert(\"RGB\")) for img_path in img_paths]\n","\n","# Stack images into a single tensor\n","images_tensor = torch.stack(images).to(device)\n","\n","print(f\"Images loaded and transformed: {images_tensor.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1nYFS9-AgAu-","executionInfo":{"status":"ok","timestamp":1712676974814,"user_tz":-330,"elapsed":593,"user":{"displayName":"Investing Filter","userId":"00097480192575946567"}},"outputId":"1f3c79aa-4448-4175-e6e9-08b1a32dece8"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Images loaded and transformed: torch.Size([3, 3, 640, 640])\n"]}]},{"cell_type":"code","source":["# Not tracking gradients\n","with torch.no_grad():\n","    predictions = model(images_tensor)"],"metadata":{"id":"Oqpc5OcLgIdz","executionInfo":{"status":"ok","timestamp":1712676978011,"user_tz":-330,"elapsed":1151,"user":{"displayName":"Investing Filter","userId":"00097480192575946567"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["from utils.plots import plot_one_box\n","from utils.general import scale_coords, non_max_suppression\n","\n","# Process predictions: Non-Max Suppression\n","predictions = non_max_suppression(predictions[0], conf_thres=0.25, iou_thres=0.45, classes=None, agnostic=False)\n","\n","for i, pred in enumerate(predictions):\n","    # Load original image\n","    img = Image.open(img_paths[i]).convert(\"RGB\")\n","    w, h = img.size\n","\n","    # Convert image to numpy array\n","    np_img = np.array(img)\n","\n","    # Scale coordinates to original dimensions\n","    pred[:, :4] = scale_coords(images_tensor[i].shape[1:], pred[:, :4], np_img.shape).round()\n","\n","    # Plot each box\n","    for *xyxy, conf, cls in reversed(pred):\n","        label = f'{class_names[int(cls)]} {conf:.2f}'\n","        plot_one_box(xyxy, np_img, label=label, color=(255, 0, 0), line_thickness=3)\n","\n","    # Display the image\n","    plt.figure(figsize=(10, 10))\n","    plt.imshow(np_img)\n","    plt.title(f\"Image {i+1}\")\n","    plt.axis('off')\n","    plt.show()"],"metadata":{"id":"-YrK4BltgLjr","executionInfo":{"status":"ok","timestamp":1712676985297,"user_tz":-330,"elapsed":4570,"user":{"displayName":"Investing Filter","userId":"00097480192575946567"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","from PIL import Image\n","from torchvision import transforms\n","import matplotlib.pyplot as plt\n","from models.experimental import attempt_load\n","from utils.general import check_img_size, set_logging, scale_coords, non_max_suppression\n","from utils.plots import plot_one_box\n","from utils.torch_utils import select_device\n","\n","# Load and transform images\n","img_paths = [\n","    '/content/drive/MyDrive/AIP Assignment 4/object_detection/test/images/IMG_2289_jpeg_jpg.rf.fe2a7a149e7b11f2313f5a7b30386e85.jpg',\n","    '/content/drive/MyDrive/AIP Assignment 4/object_detection/test/images/IMG_2301_jpeg_jpg.rf.2c19ae5efbd1f8611b5578125f001695.jpg',\n","    '/content/drive/MyDrive/AIP Assignment 4/object_detection/test/images/IMG_2319_jpeg_jpg.rf.6e20bf97d17b74a8948aa48776c40454.jpg'\n","]\n","images = [transforms.Compose([\n","             transforms.Resize((640, 640)),\n","             transforms.ToTensor(),\n","         ])(Image.open(img_path).convert(\"RGB\")) for img_path in img_paths]\n","\n","# Stack images into a single tensor\n","images_tensor = torch.stack(images).to(device)\n","print(f\"Images loaded and transformed: {images_tensor.shape}\")\n","\n","# Run inference\n","with torch.no_grad():\n","    predictions = model(images_tensor)\n","    # Assuming the detections are the first element of the output\n","    detections = predictions[0]\n","\n","predictions = non_max_suppression(detections, conf_thres=0.1, iou_thres=0.3, classes=None, agnostic=False)\n","\n","# Visualization\n","for i, pred in enumerate(predictions):\n","    print(f\"Detections for image {i+1}: {pred}\")  # Debugging statement to check detections\n","\n","    if len(pred) == 0:\n","        print(f\"No detections for image {i+1}.\")\n","        continue\n","\n","    # Load original image\n","    img = Image.open(img_paths[i]).convert(\"RGB\")\n","    w, h = img.size\n","\n","    # Convert image to numpy array for plotting\n","    np_img = np.array(img)\n","\n","    # Scale coordinates to original dimensions\n","    pred[:, :4] = scale_coords(images_tensor[i].shape[1:], pred[:, :4], np_img.shape).round()\n","\n","    # Plot each box\n","    for *xyxy, conf, cls in reversed(pred):\n","        label = f'{class_names[int(cls)]} {conf:.2f}'\n","        plot_one_box(xyxy, np_img, label=label, color=(255, 0, 0), line_thickness=3)\n","\n","    # Display the image\n","    plt.figure(figsize=(10, 10))\n","    plt.imshow(np_img)\n","    plt.title(f\"Image {i+1}\")\n","    plt.axis('off')\n","    plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WZbHB7tEgzM7","executionInfo":{"status":"ok","timestamp":1712677230159,"user_tz":-330,"elapsed":2191,"user":{"displayName":"Investing Filter","userId":"00097480192575946567"}},"outputId":"a03a954d-19fe-47d6-abe0-e9064fb07d61"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Images loaded and transformed: torch.Size([3, 3, 640, 640])\n","Detections for image 1: tensor([[1.19035e+02, 3.04966e+02, 4.50491e+02, 4.49681e+02, 1.29491e-01, 0.00000e+00]], device='cuda:0')\n","Detections for image 2: tensor([[2.86805e+02, 3.25600e+01, 3.26544e+02, 5.15231e+01, 2.87479e-01, 0.00000e+00],\n","        [3.96155e+02, 3.05944e+02, 4.27416e+02, 3.17629e+02, 2.85134e-01, 0.00000e+00],\n","        [4.57534e+02, 3.14745e+02, 4.86698e+02, 3.54441e+02, 2.78564e-01, 0.00000e+00],\n","        [2.54073e+02, 2.90758e+02, 2.80318e+02, 3.30437e+02, 2.70249e-01, 0.00000e+00],\n","        [4.46553e+02, 2.97808e+02, 4.60994e+02, 3.11847e+02, 2.69910e-01, 0.00000e+00],\n","        [5.71676e+02, 1.06798e+02, 6.09053e+02, 1.18505e+02, 2.61074e-01, 0.00000e+00],\n","        [1.77107e+02, 3.35835e+02, 2.20971e+02, 4.09769e+02, 2.10531e-01, 0.00000e+00],\n","        [3.42020e+02, 2.91703e+02, 3.70186e+02, 3.25574e+02, 2.07235e-01, 0.00000e+00],\n","        [1.52608e+02, 2.90648e+02, 1.72367e+02, 3.26589e+02, 1.88412e-01, 0.00000e+00],\n","        [1.98706e+02, 2.93122e+02, 2.21915e+02, 3.15136e+02, 1.86663e-01, 0.00000e+00],\n","        [4.58633e+02, 3.13853e+02, 4.91262e+02, 3.52643e+02, 1.85112e-01, 2.00000e+00],\n","        [2.13511e+02, 2.97655e+02, 2.56366e+02, 3.29698e+02, 1.81146e-01, 2.00000e+00],\n","        [5.28395e+02, 3.02131e+02, 5.49912e+02, 3.15695e+02, 1.78893e-01, 0.00000e+00],\n","        [2.15324e+02, 2.97381e+02, 2.50249e+02, 3.28443e+02, 1.77430e-01, 0.00000e+00],\n","        [4.71510e+02, 2.98265e+02, 4.87286e+02, 3.10969e+02, 1.70067e-01, 0.00000e+00],\n","        [1.16514e+02, 2.91968e+02, 1.54435e+02, 3.31507e+02, 1.69300e-01, 2.00000e+00],\n","        [3.75799e+02, 2.90261e+02, 3.98979e+02, 3.18885e+02, 1.67413e-01, 0.00000e+00],\n","        [1.74195e+02, 3.36099e+02, 2.28847e+02, 4.06843e+02, 1.52515e-01, 4.00000e+00],\n","        [3.36871e+02, 2.90710e+02, 3.71067e+02, 3.25018e+02, 1.51267e-01, 2.00000e+00],\n","        [5.79058e+02, 3.03463e+02, 6.08916e+02, 3.28869e+02, 1.49498e-01, 2.00000e+00],\n","        [3.17875e+02, 3.14251e+02, 3.44031e+02, 3.35860e+02, 1.48373e-01, 0.00000e+00],\n","        [2.60430e+02, 2.93265e+02, 2.78584e+02, 3.29421e+02, 1.44456e-01, 2.00000e+00],\n","        [3.76125e+02, 2.92123e+02, 4.00970e+02, 3.20130e+02, 1.40282e-01, 2.00000e+00],\n","        [5.31516e+02, 3.01857e+02, 5.64049e+02, 3.30486e+02, 1.37050e-01, 2.00000e+00],\n","        [2.79092e+02, 2.91991e+02, 3.08175e+02, 3.32948e+02, 1.31654e-01, 0.00000e+00],\n","        [5.58849e+02, 5.33770e+01, 5.96652e+02, 6.75770e+01, 1.29509e-01, 0.00000e+00],\n","        [5.81207e+02, 3.05446e+02, 6.06549e+02, 3.23565e+02, 1.17635e-01, 0.00000e+00],\n","        [2.88706e+02, 2.78165e+02, 3.09098e+02, 3.00707e+02, 1.16825e-01, 0.00000e+00],\n","        [5.02434e+02, 2.97885e+02, 5.30709e+02, 3.54451e+02, 1.16375e-01, 2.00000e+00],\n","        [4.99776e+02, 3.02207e+02, 5.19632e+02, 3.20288e+02, 1.14291e-01, 0.00000e+00],\n","        [3.33493e+02, 2.73354e+02, 3.71766e+02, 2.82041e+02, 1.09059e-01, 0.00000e+00],\n","        [1.50302e+02, 2.93231e+02, 1.72172e+02, 3.21925e+02, 1.01374e-01, 2.00000e+00],\n","        [1.72331e+02, 3.65889e+02, 1.96485e+02, 4.09705e+02, 1.00230e-01, 0.00000e+00]], device='cuda:0')\n","Detections for image 3: tensor([[3.18565e+02, 1.90074e+02, 3.74182e+02, 2.49935e+02, 4.19725e-01, 0.00000e+00],\n","        [5.45088e+02, 1.54673e+02, 5.85827e+02, 1.90587e+02, 2.33830e-01, 2.00000e+00],\n","        [4.44660e+02, 1.55736e+02, 4.82106e+02, 1.86165e+02, 1.53781e-01, 2.00000e+00],\n","        [4.30907e+02, 1.64721e+02, 4.55692e+02, 1.91091e+02, 1.49348e-01, 0.00000e+00],\n","        [5.11821e+02, 1.63485e+02, 5.36741e+02, 1.82885e+02, 1.48158e-01, 0.00000e+00],\n","        [3.13204e+02, 1.89179e+02, 3.84662e+02, 2.51685e+02, 1.41995e-01, 2.00000e+00],\n","        [5.95391e+02, 1.54202e+02, 6.18794e+02, 1.89894e+02, 1.41431e-01, 2.00000e+00],\n","        [5.48501e+02, 1.53953e+02, 5.87451e+02, 1.91504e+02, 1.30744e-01, 0.00000e+00],\n","        [3.92239e+02, 1.06691e+02, 4.18485e+02, 1.16115e+02, 1.25816e-01, 0.00000e+00],\n","        [2.43306e+02, 2.97343e+02, 3.86835e+02, 3.45867e+02, 1.16877e-01, 0.00000e+00],\n","        [5.29708e+02, 1.56772e+02, 5.45955e+02, 1.76403e+02, 1.08817e-01, 0.00000e+00]], device='cuda:0')\n"]}]},{"cell_type":"code","source":["from PIL import Image, ImageDraw, ImageFont\n","from IPython.display import display\n","\n","# Helper function to draw a single bounding box with a label\n","def draw_bbox(draw, bbox, label, color):\n","    # Draw the bounding box\n","    draw.rectangle(bbox, outline=color, width=3)\n","    try:\n","        font = ImageFont.truetype(\"arial.ttf\", 30)\n","    except IOError:\n","        font = ImageFont.load_default()  # Default font\n","\n","    # Use textbbox for text size calculation\n","    text_bbox = draw.textbbox((bbox[0], bbox[1]), label, font=font)\n","    text_width = text_bbox[2] - text_bbox[0]\n","    text_height = text_bbox[3] - text_bbox[1]\n","\n","    # Draw text background based on textbbox size\n","    draw.rectangle([bbox[0], bbox[1] - text_height, bbox[0] + text_width, bbox[1]], fill=color)\n","    # Draw text\n","    draw.text((bbox[0], bbox[1] - text_height), label, fill='white', font=font)\n","\n","# Assuming 'predictions[i]' and 'images' are already defined\n","for i, pred in enumerate(predictions):\n","    # Load original image\n","    img = Image.open(img_paths[i]).convert(\"RGB\")\n","    draw = ImageDraw.Draw(img)\n","\n","    # Scaling coordinates and drawing bboxes\n","    for *xyxy, conf, cls_id in pred.cpu().numpy():\n","        bbox = [round(x) for x in xyxy]  # Convert bbox coords to integers\n","        label = f\"{class_names[int(cls_id)]}: {conf:.2f}\"\n","        draw_bbox(draw, bbox, label, 'red')\n","\n","    # Display the image\n","    display(img)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1q_mXPSFFcQF5Wi72wFsNDXJJf2fwbek9"},"id":"2aYWPPxPkftm","executionInfo":{"status":"ok","timestamp":1712678140275,"user_tz":-330,"elapsed":19534,"user":{"displayName":"Investing Filter","userId":"00097480192575946567"}},"outputId":"fd41e65e-70ce-48ae-cdb6-3cf2e031101c"},"execution_count":59,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}